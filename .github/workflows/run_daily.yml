name: Run Daily ASSRS Data Pipeline

on:
  # 1. Run on a schedule (01:00 UTC = 9:00 AM Beijing Time)
  schedule:
    - cron: '0 1 * * *'
  # 2. Also allow manual runs from the "Actions" tab on GitHub
  workflow_dispatch:

jobs:
  build-and-commit:
    runs-on: ubuntu-latest
    
    # ---!!!--- THIS IS THE FIX ---!!!---
    # This block grants the job permission to 'push' (write)
    # changes back to your repository.
    permissions:
      contents: write
    # ---!!!--- END OF FIX ---!!!---
    
    steps:
      # 1. Check out your repository code
      - name: Check out repo
        uses: actions/checkout@v3

      # 2. Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11' 

      # 3. Restore the Database Cache
      - name: Cache and Restore SQLite Database
        uses: actions/cache@v3
        with:
          path: assrs_tushare_local.db
          key: ${{ runner.os }}-sqlite-db-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-sqlite-db-

      # 4. Install your libraries
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      # 5. Run your main.py script
      # This will find the cached .db file and *only* fetch new data.
      - name: Run ASSRS V1 and V2 Backtests
        run: |
          python main.py
          
      # 6. Commit the new CSV files back to the repo
      - name: Commit data files
        run: |
          git config --global user.name 'GitHub Action Bot'
          git config --global user.email 'action@github.com'
          git add assrs_backtest_results_SECTORS_V1_Rules.csv
          git add assrs_backtest_results_SECTORS_V2_Regime.csv
          # Only commit if there are changes
          git diff --quiet && git diff --staged --quiet || (git commit -m "Data: Automated daily signal update" && git push)
          echo "Data push complete."
